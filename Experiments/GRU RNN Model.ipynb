{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "067d18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ee6379dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "053183b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                                        review_body  sentiment\n",
      "0  0                                                  0          0\n",
      "1  1                 love watch keeps time wonderfully.          1\n",
      "2  2                                          scratches          2\n",
      "3  3  works well me. however, found cheaper prices p...          1\n",
      "4  4  beautiful watch face. band looks nice around. ...          1\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Final.csv')\n",
    "\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0e48401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    data['review_body'] = data['review_body'].str.strip().str.lower()\n",
    "    return data\n",
    "\n",
    "data = preprocess_data(data)\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b51c4178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['review_body'] = data['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "99aefa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0                                        review_body  sentiment\n",
      "0          0                                                 0           0\n",
      "1          1                 love watch keep time wonderfully.           1\n",
      "2          2                                           scratch           2\n",
      "3          3  work well me. however, found cheaper price pla...          1\n",
      "4          4  beautiful watch face. band look nice around. l...          1\n",
      "...      ...                                                ...        ...\n",
      "15707  15707  purchased watch amazon promotion. would equall...          1\n",
      "15708  15708  ordered watch wed. got sunday. watch rather ea...          1\n",
      "15709  15709  love size perfect toddler four year old love it.           1\n",
      "15710  15710                                              fine           1\n",
      "15711  15711  experience material tool staff buy amazon neve...          1\n",
      "\n",
      "[15691 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "data['review_body'] = data.review_body.apply(lemmatize_text)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d7fb342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data['review_body'].values\n",
    "labels = data['sentiment'].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2f833eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf6f1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the model\n",
    "vocab_size = 3000 # choose based on statistics\n",
    "oov_tok = ''\n",
    "embedding_dim = 200\n",
    "max_length = 200 # choose based on statistics, for example 150 to 200\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "# tokenize sentences\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "# convert train dataset to sequence and pad sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "# convert Test dataset to sequence and pad sequences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "51f773ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, 200, 25)           75000     \n",
      "                                                                 \n",
      " gru_30 (GRU)                (None, 128)               59520     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,649\n",
      "Trainable params: 134,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "331/331 [==============================] - 100s 294ms/step - loss: -0.1282 - accuracy: 0.7735 - val_loss: -0.3838 - val_accuracy: 0.7638\n",
      "Epoch 2/5\n",
      "331/331 [==============================] - 105s 316ms/step - loss: -0.5428 - accuracy: 0.7735 - val_loss: -0.4512 - val_accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "331/331 [==============================] - 99s 300ms/step - loss: -0.6217 - accuracy: 0.7735 - val_loss: -0.5092 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "331/331 [==============================] - 100s 301ms/step - loss: -0.6918 - accuracy: 0.7735 - val_loss: -0.5588 - val_accuracy: 0.7638\n",
      "Epoch 5/5\n",
      "331/331 [==============================] - 105s 317ms/step - loss: -0.7548 - accuracy: 0.7735 - val_loss: -0.6071 - val_accuracy: 0.7638\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-25e01794e130>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Printing model score on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GRU model Score---> \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgru_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_labels' is not defined"
     ]
    }
   ],
   "source": [
    "max_words = 200\n",
    "embd_len = 25\n",
    "# Defining GRU model\n",
    "gru_model = Sequential(name=\"GRU_Model\")\n",
    "gru_model.add(Embedding(vocab_size,\n",
    "                        embd_len,\n",
    "                        input_length=max_words))\n",
    "gru_model.add(GRU(128,\n",
    "                  activation='tanh',\n",
    "                  return_sequences=False))\n",
    "gru_model.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "# Printing the Summary\n",
    "print(gru_model.summary())\n",
    " \n",
    "# Compiling the model\n",
    "gru_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics = [tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    " \n",
    "# Training the GRU model\n",
    "num_epochs = 5\n",
    "history = gru_model.fit(train_padded, train_labels, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_split=0.1)\n",
    " \n",
    "# Printing model score on test data\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "70aeb2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 9s 68ms/step\n",
      "Accuracy of prediction on test set :  0.7723680856487382\n"
     ]
    }
   ],
   "source": [
    "prediction = gru_model.predict(test_padded)\n",
    "# Get labels based on probability 1 if p>= 0.5 else 0\n",
    "pred_labels = []\n",
    "for i in prediction:\n",
    "    if i == 1:\n",
    "        pred_labels.append(1)\n",
    "    elif i == 2:\n",
    "        pred_labels.append(2)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f609a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae384a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
